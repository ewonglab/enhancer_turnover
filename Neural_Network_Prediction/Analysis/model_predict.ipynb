{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58e12cb-541f-4874-b562-f2621a6eb4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2022-10-10 15:55:50.042301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# Test data loading and model loading and prediction\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append(\"/g/data/zk16/xzhang/cross-species-domain-adaptation/3_manuscript_figure_and_table_notebooks\")\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1e5489d-3049-4cbe-bdb9-8b8b0099a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/g/data/zk16/xzhang/cross-species-domain-adaptation/\"\n",
    "\n",
    "# shorthand for each TF name\n",
    "# tfs = [\"CEBPA\", \"Hnf4a\"]\n",
    "tfs = [\"CEBPA\"]\n",
    "# tfs = [\"Hnf4a\"]\n",
    "\n",
    "# shorthand names for all model training types to generate predictions for\n",
    "all_trainspecies = [\"DA\"]\n",
    "\n",
    "# these are specifically the \"species\" with test datasets to evaluate on\n",
    "# all_testspecies = [\"mm10\", \"hg38\"]\n",
    "# all_testspecies = [\"hg38\"]\n",
    "all_testspecies = [\"mm10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e00788-26ed-43b9-b587-66dc77a55cd1",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfb60de3-7c68-4a75-b8b1-6ac73c0be79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from seqdataloader.batchproducers.coordbased.core import Coordinates\n",
    "from seqdataloader.batchproducers.coordbased.coordstovals.fasta import PyfaidxCoordsToVals\n",
    "\n",
    "#TODO: add your own genome PATH\n",
    "GENOMES = {\"mm10\" : \"/g/data/zk16/xzhang/cross-species-domain-adaptation/genome_data/Mus_musculus.GRCm38.dna_sm.primary_assembly.fa\",\n",
    "            \"hg38\" : \"/g/data/zk16/xzhang/cross-species-domain-adaptation/genome_data/hg38.fa\"}\n",
    "\n",
    "#TODO: add your own test file PATH\n",
    "get_test_bed_file = \"/g/data/zk16/xzhang/cross-species-domain-adaptation/data/mm10/CEBPA/chr2.bed\" \n",
    "\n",
    "# get_test_bed_file = \"/g/data/zk16/xzhang/cross-species-domain-adaptation/test_data/data1_paola/human_enhancers_hg38_functional.bed\" \n",
    "# get_test_bed_file = \"/g/data/zk16/xzhang/cross-species-domain-adaptation/test_data/data2_removed_paola/Mmus_Enhancers_not_Hsap_alignHsap_mm10_w500.bed\"\n",
    "# get_test_bed_file = \"/g/data/zk16/xzhang/cross-species-domain-adaptation/test_data/data3_extended_paola/Hsap_Enhancers_not_Mmus_alignMmus_mm10_w500_ext.bed\"\n",
    "\n",
    "# Hsap_Enhancers_not_Mmus_alignMmus_hg38_w500.bed\"\n",
    "\n",
    "# def get_test_bed_file(species):\n",
    "#     # This function returns the path to a BED-format file\n",
    "#     # containing the chromosome names, starts, and ends for\n",
    "#     # all examples to test the model with.\n",
    "#     # Note binding labels will not be loaded in.\n",
    "#     # This file should contain the same examples for any TF.\n",
    "#     return(ROOT + \"data/\" + species + \"/\" + tfs[0] + \"/chr2.bed\")\n",
    "\n",
    "\n",
    "class ValGenerator(Sequence):\n",
    "    # This generator retrieves all coordinates for windows in the test set\n",
    "    # and converts the sequences in those windows to one-hot encodings.\n",
    "    # Which species to retrieve test windows for is specified with\n",
    "    # the \"val_species\" argument. \n",
    "    \n",
    "    def __init__(self, batchsize, val_species = \"hg38\"):\n",
    "    # def __init__(self, batchsize, val_species = \"mm10\"):\n",
    "        print(val_species + \"inside valgenerator\")\n",
    "        self.valfile = get_test_bed_file\n",
    "        self.get_steps(batchsize)\n",
    "        self.converter = PyfaidxCoordsToVals(GENOMES[val_species])\n",
    "        self.batchsize = batchsize\n",
    "        self.get_coords()\n",
    "        \n",
    "        \n",
    "    def get_steps(self, batchsize):\n",
    "        # calculates the number of steps needed to get through\n",
    "        # all batches of examples in the test dataset\n",
    "        # (Keras predict_generator code needs to know this)\n",
    "        with open(self.valfile) as f:\n",
    "            lines_in_file = sum(1 for line in f)\n",
    "        \n",
    "        self.steps = lines_in_file // batchsize\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def get_coords(self):\n",
    "        # load all coordinates for the test data into memory\n",
    "        with open(self.valfile) as f:\n",
    "            coords_tmp = [line.rstrip().split()[:3] for line in f]\n",
    "            \n",
    "        assert [len(line_split) == 3 for line_split in coords_tmp]\n",
    "        self.coords = [Coordinates(coord[0], int(coord[1]), int(coord[2])) for coord in coords_tmp]\n",
    "\n",
    "    def __getitem__(self, batch_index):\n",
    "        # convert a batch's worth of coordinates into one-hot sequences\n",
    "        batch = self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
    "        return self.converter(batch)\n",
    "    \n",
    "\n",
    "# def get_preds_batched_fast(model, batch_size, test_species = \"mm10\"):\n",
    "def get_preds_batched_fast(model, batch_size, test_species = \"hg38\"):\n",
    "    # Make predictions for all test data using a specified model.\n",
    "    # Batch_size can be as big as your compute can handle.\n",
    "    # Use test_species = \"mm10\" to test on mouse data instead of human data.\n",
    "    \n",
    "    print(\"Generating predictions... \" + test_species)\n",
    "    return np.squeeze(model.predict_generator(ValGenerator(batch_size, test_species),\n",
    "                                               use_multiprocessing = True, workers = 8, verbose = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a88ab2-b83d-47d5-b1d0-345fa2447beb",
   "metadata": {},
   "source": [
    "Model LoadingÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bcae298-bc41-467c-82fe-6d70fb3bf2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed to load DA models\n",
    "\n",
    "from flipGradientTF import GradientReversal\n",
    "import tensorflow\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # this should be the same implementation as what was used when the DA model trained\n",
    "    y_pred = tensorflow.boolean_mask(y_pred, tensorflow.not_equal(y_true, -1))\n",
    "    y_true = tensorflow.boolean_mask(y_true, tensorflow.not_equal(y_true, -1))\n",
    "    return keras.losses.binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4965e803-759a-4a0d-a3a4-06c3673c523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_file(tf, train_species, run = 1, model_type = \"best\"):\n",
    "    # This function returns the filepath where the model for a given\n",
    "    # TF, training species, and run is saved.\n",
    "    # By default, the file for the best model across all training epochs\n",
    "    # is returned, you can change model_type to select the last model instead.\n",
    "    # This function specifically looks for the most recent model file,\n",
    "    # if there are multiple for the same run-TF-species combo.\n",
    "    try:\n",
    "        run_int = int(run)\n",
    "    except:\n",
    "        print(\"Error: You need to pass in a run number that can be cast to int.\")\n",
    "    \n",
    "    model_file_prefix = ROOT + \"/\".join([\"models\", tf, train_species + \"_trained\", \"basic_model/\"])\n",
    "        \n",
    "    if train_species == \"DA\":\n",
    "        # assuming all DA models are mouse-trained\n",
    "        # model_file_prefix = model_file_prefix.replace(\"DA\", \"mm10\")  \n",
    "        # change DA models to human-trained\n",
    "        model_file_prefix = model_file_prefix.replace(\"DA\", \"hg38\")  \n",
    "        model_file_prefix = model_file_prefix.replace(\"basic_model\", \"DA\")\n",
    "    if train_species == \"NS\":\n",
    "        # assuming the no-SINEs models are trained on human data\n",
    "        model_file_prefix = model_file_prefix.replace(\"basic_model\", \"basic_model_nosines\")\n",
    "        model_file_prefix = model_file_prefix.replace(\"NS\", \"hg38\")        \n",
    "    \n",
    "    # these models were saved as part of training\n",
    "    # see ../2_train_and_test_models/callbacks.py for model saving details \n",
    "    if model_type == \"best\":\n",
    "        model_file_suffix = \"_run\" + str(run) + \"_best.model\"\n",
    "    else:\n",
    "        model_file_suffix = \"_run\" + str(run) + \"_15E_end.model\"\n",
    "    \n",
    "    # get all files that match the prefix and suffix\n",
    "    files = [f for f in os.listdir(model_file_prefix) if f.endswith(model_file_suffix)]\n",
    "    \n",
    "    # sort files and return the one that is most recent\n",
    "    latest_file = max([model_file_prefix + f for f in files], key=os.path.getctime)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "def load_keras_model(model_file, DA = False):\n",
    "    print(\"Loading \" + model_file + \".\")\n",
    "    if DA:\n",
    "        # need to tell Keras how the GRL and the custom loss was implemented\n",
    "        # (these need to match the definitions from when the model was saved)\n",
    "        return keras.models.load_model(model_file,\n",
    "                custom_objects = {\"GradientReversal\":GradientReversal,\n",
    "                                  \"custom_loss\":custom_loss})\n",
    "    return keras.models.load_model(model_file)\n",
    "\n",
    "\n",
    "def get_models_all_runs(tf, train_species, runs = 1):\n",
    "    # load in models for all runs, for a given TF and training species\n",
    "    # returns a list of Keras model objects\n",
    "    models = []\n",
    "    for run in range(runs):\n",
    "        model_file = get_model_file(tf, train_species, run + 1)\n",
    "        print(model_file)\n",
    "        models.append(load_keras_model(model_file, DA = train_species == \"DA\"))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb8b0b-9f2f-444d-bf2b-3d875e5428a5",
   "metadata": {},
   "source": [
    "Generate + Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0641e53d-632f-4409-8ee2-7e2d8bdc979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_file(tf, train_species, test_species):\n",
    "    preds_root = ROOT + \"model_out/\"\n",
    "    os.makedirs(preds_root, exist_ok=True)\n",
    "    # return preds_root + tf + \"_\" + train_species + \"-hgtrained_\" + test_species + \"-test_HE.preds\"\n",
    "    return preds_root + tf + \"_MouseChr2_hgtrained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b965136-4b8d-442b-94ec-86752b064556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CEBPA mm10 test, DA trained =====\n",
      "\n",
      "/g/data/zk16/xzhang/cross-species-domain-adaptation/models/CEBPA/hg38_trained/DA/2022-10-08_01-46-33_run1_best.model\n",
      "Loading /g/data/zk16/xzhang/cross-species-domain-adaptation/models/CEBPA/hg38_trained/DA/2022-10-08_01-46-33_run1_best.model.\n",
      "Generating predictions... mm10\n",
      "mm10inside valgenerator\n",
      "3000/3000 [==============================] - 465s 155ms/step\n"
     ]
    }
   ],
   "source": [
    "### This cell takes a while (hours) to run.\n",
    "\n",
    "# loop over mouse and human, the two species to evaluate models in\n",
    "for test_species in all_testspecies:\n",
    "    # loop over mouse-trained, human-trained models\n",
    "    for train_species in all_trainspecies:  \n",
    "        for tf in tfs:\n",
    "            print(\"\\n===== \" + tf + \" \" + test_species + \" test, \" + train_species + \" trained =====\\n\")\n",
    "\n",
    "            # load the 5 independently trained models for the given tf and training species\n",
    "            # here only test DA models\n",
    "            models = get_models_all_runs(tf, train_species)\n",
    "        \n",
    "            # generate predictions for all 5 independent model runs on human data\n",
    "            all_model_preds = np.array([get_preds_batched_fast(model, 1024, test_species = test_species) for model in models])\n",
    "            \n",
    "            # if we got the output of DA model, throw out species preds and keep binding preds\n",
    "            if train_species == \"DA\" and len(all_model_preds.shape) > 2:\n",
    "                all_model_preds = all_model_preds[:, 0, :]\n",
    "            assert len(all_model_preds.shape) == 2, all_model_preds.shape\n",
    "            \n",
    "            # save predictions to file\n",
    "            preds_file = get_preds_file(tf, train_species, test_species)\n",
    "            np.save(preds_file, all_model_preds.T)\n",
    "\n",
    "            # clear variables and model to avoid unnecessary memory usage\n",
    "            del all_model_preds, tf, models\n",
    "            keras.backend.clear_session()\n",
    "        del train_species\n",
    "    del test_species"
   ]
  }
 
